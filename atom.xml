<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[BI blog 4U]]></title>
  <link href="http://narusou.github.io/atom.xml" rel="self"/>
  <link href="http://narusou.github.io/"/>
  <updated>2017-07-18T15:38:44+09:00</updated>
  <id>http://narusou.github.io/</id>
  <author>
    <name><![CDATA[Souichi Narumiya]]></name>
    <email><![CDATA[narumiyasouichi@yahoo.co.jp]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Data Processing With Spark in R &amp; Python]]></title>
    <link href="http://narusou.github.io/blog/2017/07/18/data-processing-with-spark-in-r-and-python/"/>
    <updated>2017-07-18T14:57:39+09:00</updated>
    <id>http://narusou.github.io/blog/2017/07/18/data-processing-with-spark-in-r-and-python</id>
    <content type="html"><![CDATA[<h3>原文</h3>

<p>I recently gave a talk on data processing with Apache Spark using R and Python. tl;dr – the slides and presentation can be accessed below:<br/>
<a href="https://www.brighttalk.com/webcast/9059/172833">https://www.brighttalk.com/webcast/9059/172833</a></p>

<p>As noted in my previous post, Spark has become the defacto standard for big data applications   and has been adopted quickly by the industry. See Cloudera’s  One Platform initiative blog post by CEO Mike Olson for their commitment to Spark.　In data science R had seen rapid adoption, not only because it was open source and free   compared to costly SAS, but also the huge number of statistical and graphical packages provided　by R for data science. The most popular ones of course are the ones from Hadley Wickham (dplyr,　ggplot2, reshape2, tidyr and more). On the other hand, Python had seen rapid adoption among　developers and engineers due to its being useful to script big data tasks along with data　analysis with the help of packages like pandas, scikit-learn, NumPy, SciPy, matplotlib etc.　and also the popular iPython &amp; later Jupyter notebooks.　</p>

<p>There are numerous posts strewn on the net picking fights between R and Python. However it is quite usual for any big data and data science shop to have developers and data scientists who use either or both these tools. Spark makes it easy for both communities to leverage the power of Hadoop and distributed processing systems with its own APIs like DataFrames which can be used in a polyglot fashion. Therefore it is essential for any data enthusiast to learn about how data processing in Spark can be done using R or Python.</p>

<h3>翻訳</h3>

<p>最近、RとPythonを使用したApatche Sparkによるデータプロセスに関して話をした。下記のURLからスライドとプレゼンテーションにアクセス可能。<br/>
<a href="https://www.brighttalk.com/webcast/9059/172833">https://www.brighttalk.com/webcast/9059/172833</a></p>

<p>過去の投稿にあるように、Sparkはビックデータアプリケーションの事実上のスタンダードになり、また急速にBI業界に取り入れられた経緯がある。CEO Mike Olsonによる彼らのSparkへのコミットメントに関するブログ投稿を参照。
データサイエンスに関して、RはコストがかかるSASに比べてフリーでオープンソースであるという理由のみならず、データサイエンスのために用意された統計的でグラフィカルな数多くのパッケージによって急速に普及してきた。もっともよく知られている事例としてはHadley Wickham(dplyr, ggplot2, reshape2, tidyr and more)による。一方、Pythonは開発者とエンジニアの間で、Pandaやscikit-learn、NumPy, SciPy,matplotlibとかのようなパッケージによってデータアナリシスにおけるビッグデータのタスクを記述するのに便利であるため急速に採用されてきた。そして、iPython, 後期のJupiter notebooksによるものがよく知られている。</p>

<p>非常に多くのRとPythonに関する両社の批判や議事が散らばった投稿として見受けられる。しかし、これらを同時に両方、もしくは二種類を使用するデータサイエンティストと開発者達を保有するのはデータサイエンスやビッグデータを生業にするものにとってはかなり普通のことと思われる。SparkはHadoopの力と、多言語仕様で使用することが出来るデータフレームのようなSparkのAPIと、それを使用したディストリビューションのプロセスシステムを、この両者のコミュニティが利用することを簡単にする。それゆえ、RとPyhonによるSparkが行うデータプロセスがどのようなものなのかを学ぶことはデータマニアにとっては必要不可欠なことだと思われる。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Translation1]]></title>
    <link href="http://narusou.github.io/blog/2017/07/18/translation1/"/>
    <updated>2017-07-18T14:56:11+09:00</updated>
    <id>http://narusou.github.io/blog/2017/07/18/translation1</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Test]]></title>
    <link href="http://narusou.github.io/blog/2017/07/15/test/"/>
    <updated>2017-07-15T22:20:27+09:00</updated>
    <id>http://narusou.github.io/blog/2017/07/15/test</id>
    <content type="html"><![CDATA[<p>This site is created for my practice to develop homepages and traslate articles about Business Intelligence.</p>

<!--more-->


<p><img src="http://narusou.github.io/images/test.png" alt="test" /></p>

<h2>環境</h2>

<p>PC:HPchromebook<br/>
OS:Google Chrome and UBUNTU 14.04 LTS</p>

<h2>OctPressをGITHUBにdeployするためにしたこと</h2>

<pre><code>1,githubにブランチ作成
2,rbenvのインストール
3,rubｙのインストール
4,githubとlocalの同期
5,rakeで記事の作成
6,generate, deploy
</code></pre>

<h2>躓いた点</h2>

<p> ・rubyとrbenv versionの整理<br/>
 ・git pull</p>

<h2>使用したコード 順不同</h2>

<pre><code>$ rake deploy
$ rake generate
$ ruby -v
$ ruby --version
$ rbenv versions
$ rbenv version
$ source ~/.bash_profile
$ echo $PATH
$ which ruby
$ which rbenv
$ rbenv init
$ rbenv global 2.4.1
$ bundle exec 
$ git pull
$ git push
$ git commit
$ sudo apt-get install ruby
$ sudo apt-get install git
$ git clone git://github.com/sstephenson/rbenv.git ~/.rbenv
$ git clone https://github.com/sstephenson/ruby-build.git ~/.rbenv/plugins/ruby-build
$ echo 'export PATH="$HOME/.rbenv/bin:$PATH"' &gt;&gt; ~/.profile
$ echo 'eval "$(rbenv init -)"' &gt;&gt; ~/.profile
$ exec $SHELL -l
$ rbenv install -l
$ rbenv install 2.4.1
$ rbenv exec gem install bundler
$ rbenv rehash
$ git clone git://github.com/imathis/octopress.git octopress
$ cd octopress
$ bundle install --path vendor/bundle
$ git clone git://github.com/lucaslew/whitespace.git .themes/whitespace
$ rake install['whitespace'] # for zsh, use: rake install\['whitespace'\]
$ rake new_post['test']
$ rake preview
$ rake setup_github_pages
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First_test]]></title>
    <link href="http://narusou.github.io/blog/2017/07/15/first-test/"/>
    <updated>2017-07-15T21:36:23+09:00</updated>
    <id>http://narusou.github.io/blog/2017/07/15/first-test</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
</feed>
